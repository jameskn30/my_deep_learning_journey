{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMY9ffu99UvghW+g1pfJT3c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KUyfyH4_X_zS"},"outputs":[],"source":["!pip install setuptools==66\n","!pip install matplotlib_inline\n","!pip install d2l==1.0.0b"]},{"cell_type":"code","source":["import os\n","import re\n","import torch\n","from torch import nn\n","from d2l import torch as d2l"],"metadata":{"id":"3dF1HPjGY1rK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["d2l.DATA_HUB['SNLI'] = (\n","    'https://nlp.stanford.edu/projects/snli/snli_1.0.zip',\n","    '9fcde07509c7e87ec61c640c1b2753d9041758e4')\n","data_dir = d2l.download_extract('SNLI')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SMo5SVxGbGv4","executionInfo":{"status":"ok","timestamp":1680882870233,"user_tz":240,"elapsed":14563,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"outputId":"290116cf-fdcf-4848-88b5-576bc4d00665"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading ../data/snli_1.0.zip from https://nlp.stanford.edu/projects/snli/snli_1.0.zip...\n"]}]},{"cell_type":"code","source":["#Read the dataset\n","# NOte that in order to come up with this cleaning\n","# the author has to do EDA first see what the dataset looks like\n","# it's okay to copy and paste here without understanding \n","# but when you work in real dataset, you have do EDA yourself\n","def read_snli(data_dir, is_train):\n","\n","  def extract_text(s):\n","    s = re.sub('\\\\(', '', s)\n","    s = re.sub('\\\\)', '', s)\n","    s = re.sub('\\\\s{2,}', ' ', s)\n","\n","    return s.strip()\n","\n","  label_set = {'entailment': 0, 'contradiction': 1, 'neutral': 2}\n","  file_name = os.path.join(data_dir, 'snli_1.0_train.txt' if is_train else 'snli_1.0_test.txt')\n","\n","  with open(file_name, 'r') as f:\n","      lines = f.readlines()\n","      rows = [row.split('\\t') for row in lines[1:]]\n","    \n","  premises = [extract_text(row[1]) for row in rows if row[0] in label_set]\n","  hypotheses = [extract_text(row[2]) for row in rows if row[0] in label_set]\n","  labels = [label_set[row[0]] for row in rows if row[0] in label_set]\n","\n","  return premises, hypotheses, labels\n","\n","train_data = read_snli(data_dir, True)\n","\n","for x0, x1, y in zip(train_data[0][:3], train_data[1][:3], train_data[2][:3]):\n","  print('premise:', x0)\n","  print('hypothesis:', x1)\n","  print('label:', y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cXXXw1TfbOW4","executionInfo":{"status":"ok","timestamp":1680884700301,"user_tz":240,"elapsed":16272,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"outputId":"8a0ef970-1646-4719-ab6d-4b89bb1d1437"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["premise: A person on a horse jumps over a broken down airplane .\n","hypothesis: A person is training his horse for a competition .\n","label: 2\n","premise: A person on a horse jumps over a broken down airplane .\n","hypothesis: A person is at a diner , ordering an omelette .\n","label: 1\n","premise: A person on a horse jumps over a broken down airplane .\n","hypothesis: A person is outdoors , on a horse .\n","label: 0\n"]}]},{"cell_type":"code","source":["test_data = read_snli(data_dir, is_train = False)\n","for data in [train_data, test_data]:\n","  print([[row for row in data[2]].count(i) for i in range(3)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFRZKcqxcXYz","executionInfo":{"status":"ok","timestamp":1680883528829,"user_tz":240,"elapsed":676,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"outputId":"c81a12c5-e4d2-469c-d827-6fb62bea50c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["sample raw line =  neutral\t( ( This ( church choir ) ) ( ( ( sings ( to ( the masses ) ) ) ( as ( they ( ( sing ( joyous songs ) ) ( from ( ( the book ) ( at ( a church ) ) ) ) ) ) ) ) . ) )\t( ( The church ) ( ( has ( cracks ( in ( the ceiling ) ) ) ) . ) )\t(ROOT (S (NP (DT This) (NN church) (NN choir)) (VP (VBZ sings) (PP (TO to) (NP (DT the) (NNS masses))) (SBAR (IN as) (S (NP (PRP they)) (VP (VBP sing) (NP (JJ joyous) (NNS songs)) (PP (IN from) (NP (NP (DT the) (NN book)) (PP (IN at) (NP (DT a) (NN church))))))))) (. .)))\t(ROOT (S (NP (DT The) (NN church)) (VP (VBZ has) (NP (NP (NNS cracks)) (PP (IN in) (NP (DT the) (NN ceiling))))) (. .)))\tThis church choir sings to the masses as they sing joyous songs from the book at a church.\tThe church has cracks in the ceiling.\t2677109430.jpg#1\t2677109430.jpg#1r1n\tneutral\tcontradiction\tcontradiction\tneutral\tneutral\n","\n","[183416, 183187, 182764]\n","[3368, 3237, 3219]\n"]}]},{"cell_type":"code","source":["class SNLIDataset(torch.utils.data.Dataset):\n","\n","  def __init__(self, dataset, num_steps, vocab = None):\n","    self.num_steps = num_steps\n","    all_premise_tokens = d2l.tokenize(dataset[0])\n","    all_hypothesis_tokens = d2l.tokenize(dataset[1])\n","    if vocab is None:\n","      #if vocab is None, build one with all tokens from premise and hypothesis\n","      self.vocab = d2l.Vocab(all_premise_tokens + all_hypothesis_tokens, min_freq = 5, reserved_tokens=['<pad>'])\n","    else:\n","      self.vocab = vocab\n","    \n","    self.premises = self._pad(all_premise_tokens)\n","    self.hypotheses = self._pad(all_hypothesis_tokens)\n","    self.labels = torch.tensor(dataset[2])\n","\n","    print('read ' + str(len(self.premises)) + ' examples')\n","  \n","  def _pad(self, lines):\n","    return torch.tensor([d2l.truncate_pad(self.vocab[line], self.num_steps, self.vocab['<pad>']) for line in lines])\n","  \n","  def __getitem__(self, idx):\n","    return (self.premises[idx], self.hypotheses[idx], self.labels[idx])\n","  \n","  def __len__(self):\n","    return len(self.premises)\n"],"metadata":{"id":"2NtkMnWrdzC-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_data_snli(batch_size, num_steps = 50):\n","  num_workers = d2l.get_dataloader_workers()\n","  data_dir = d2l.download_extract('SNLI')\n","  train_data = read_snli(data_dir, True)\n","  test_data = read_snli(data_dir, False)\n","\n","  train_set = SNLIDataset(train_data, num_steps)\n","  test_set = SNLIDataset(test_data, num_steps)\n","\n","  train_iter = torch.utils.data.DataLoader(train_set, batch_size, shuffle = True, num_workers = num_workers)\n","  test_iter = torch.utils.data.DataLoader(test_set, batch_size, shuffle = True, num_workers = num_workers)\n","\n","  #NOTE in the book: \n","  # any new token from the testing set will be unknown to the model trained on the training set.\n","  return train_iter, test_iter, train_set.vocab\n","\n","train_iter, tets_iter, vocab = load_data_snli(128, 50)\n","\n","print('len vocab = ', len(vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L9N6xI_ChBFW","executionInfo":{"status":"ok","timestamp":1680885781866,"user_tz":240,"elapsed":54477,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"outputId":"f2d582da-2a75-49ef-83a8-8bf95662731c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["read 549367 examples\n","read 9824 examples\n","len vocab =  18678\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"1P2-8CRLh9hz"},"execution_count":null,"outputs":[]}]}