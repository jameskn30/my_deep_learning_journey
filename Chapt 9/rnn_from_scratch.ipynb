{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN9JntB4sIMXhvqDf5PL+eo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Setup env\n","!pip install d2l==1.0.0b0\n","!pip install matplotlib_inline"],"metadata":{"id":"I2BmhJBGwhdq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Chapter 9.2 Dive to Deep Learning \n","https://d2l.ai/chapter_recurrent-neural-networks/text-sequence.html\n","# Convert Text into Sequence\n"],"metadata":{"id":"1AAUGdRawAwq"}},{"cell_type":"code","source":["%matplotlib inline\n","import math\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from d2l import torch as d2l\n","import re\n"],"metadata":{"id":"6ylczNH6wzRy","executionInfo":{"status":"ok","timestamp":1676817664251,"user_tz":300,"elapsed":179,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["### Download H.G Well's Time Machine \n","class TimeMachine(d2l.DataModule):\n","    \"\"\"The Time Machine dataset.\"\"\"\n","    def _download(self):\n","        fname = d2l.download(d2l.DATA_URL + 'timemachine.txt', self.root,\n","                             '090b5e7e70c295757f55df93cb0a180b9691891a')\n","        with open(fname) as f:\n","            return f.read()\n","\n","    def _preprocess(self, text):\n","      return re.sub('[^A-Za-z]+', ' ', text).lower()\n","\n","data = TimeMachine()\n","raw_text = data._download()\n","raw_text[:60]\n","timemachine = data._preprocess(raw_text)\n","\n","print(timemachine[:60])"],"metadata":{"id":"tClrFWZwnRXs","executionInfo":{"status":"ok","timestamp":1676817677600,"user_tz":300,"elapsed":154,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"93b91f7f-5660-45ec-db65-bd6d7d9753da"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["the time machine by h g wells i the time traveller for so it\n"]}]},{"cell_type":"code","source":["#Implement RNN from scratch\n","class RNN(d2l.Module):\n","  def __init__(self, num_inputs, num_hiddens, batch_size, sigma = 0.001):\n","     # num_inputs = d \n","     # num_hiddens = h\n","     # batch_size = n\n","     super().__init__()\n","     self.save_hyperparameters()\n","     #init W_xh with shape ( d x h )\n","     self.W_xh = nn.Parameter(torch.randn((num_inputs, num_hiddens)) * sigma)\n","     #int W_hh\n","     self.W_hh = nn.Parameter(torch.randn((num_hiddens, num_hiddens)) * sigma)\n","     #init b_h \n","     self.b_h = nn.Parameter(torch.zeros(num_hiddens))\n","     \n","  def forward(self, inputs, state = None):\n","    if state == None:\n","      state = torch.zeros((self.batch_size, self.num_hiddens), device = inputs.device)\n","    else:\n","      state, = state\n","    outputs = []\n","    for X in inputs:\n","      state = torch.tanh(torch.matmul(X, self.W_xh) + torch.matmul(state, self.W_hh) + self.b_h)\n","      outputs.append(state)\n","    return outputs, state\n","    \n","\n","d = 16\n","n = 2\n","h = 32\n","steps = 100\n","\n","rnn = RNN(d, h, n)"],"metadata":{"id":"QWdJwzWDfnp1","executionInfo":{"status":"ok","timestamp":1676817681438,"user_tz":300,"elapsed":2,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["X = torch.ones((steps, n, d))\n","print(X.shape)\n","outputs, state = rnn(X, None)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TV9eDeeKhcoi","executionInfo":{"status":"ok","timestamp":1676817683036,"user_tz":300,"elapsed":488,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"outputId":"cb102168-e249-4bb0-83c7-0a6e904cb6bb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 2, 16])\n"]}]},{"cell_type":"code","source":["print('output shape (steps, n, h)')\n","print(len(outputs),',',len(outputs[0]),',',len(outputs[0][1]))\n","print('state shape (n, h)')\n","print(state.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82G2TAGBjO53","executionInfo":{"status":"ok","timestamp":1676817683205,"user_tz":300,"elapsed":4,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"outputId":"45b59d11-c70e-433b-dccc-913786c88da2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["output shape (steps, n, h)\n","100 , 2 , 32\n","state shape (n, h)\n","torch.Size([2, 32])\n"]}]},{"cell_type":"code","source":["class RNNLanguageModel(d2l.Classifier):\n","  def __init__(self, rnn, vocab_size, lr = 0.0001):\n","    super().__init__()\n","    self.save_hyperparameters()\n","    self.init_params()\n","\n","  def init_params(self):\n","     self.W_hq = nn.Parameter(torch.randn((self.rnn.num_hiddens, self.vocab_size)) * self.rnn.sigma)\n","     self.b_q = nn.Parameter(torch.zeros(self.vocab_size))\n","    \n","  def training_steps(self, batch):\n","    l = self.loss(self(*batch[-1]), batch[-1])\n","    self.plot('ppl', torch.exp(l), train = True)\n","    return l\n","  \n","  def validation_steps(self, batch):\n","    l = self.loss(self(*batch[:-1]), batch[-1])\n","    self.plot('ppl', torch.exp(l), train=False)\n","  \n","  def one_hot(self, X):\n","    return F.one_hot(X.T, self.vocab_size).type(torch.float32)\n","\n","  def output_layer(self, rnn_outputs):\n","    outputs = [torch.matmul(H, self.W_hq) + self.b_q for H in rnn_outputs]\n","    return outputs\n","  \n","  def forward(self, X, state = None):\n","    embs = self.one_hot(X)\n","    rnn_outputs, state = self.rnn(embs, state)\n","    return self.output_layer(rnn_outputs)\n","\n","@d2l.add_to_class(d2l.Trainer)\n","def clip_grad(self, grad_clip_val, model):\n","  params = [p for p in model.parameters() if p.requires_grad]\n","  norm = torch.sqrt(sum(torch.sum((p.grad ** 2)) for p in params))\n","  if norm > grad_clip_val:\n","    for param in params:\n","      param.grad[:] *= grad_clip_val / norm\n","\n","\n","model = RNNLanguageModel(rnn, d)\n","sample_input = torch.ones((n, steps), dtype=torch.int64)\n","\n","output = model(sample_input)\n","\n","print('output shape: [{},{},{}]'.format(len(output), len(output[0]), len(output[0][0])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0hl3O-TikpLt","executionInfo":{"status":"ok","timestamp":1676817684524,"user_tz":300,"elapsed":3,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"outputId":"8aecc46a-47de-4925-d6e0-aa8ca208b6b6"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["output shape: [100,2,16]\n"]}]},{"cell_type":"code","source":["#Train model\n","#Get data from d2l\n","\n","n = 1024\n","steps = 32\n","h = 32\n","\n","data = d2l.TimeMachine(n, steps)\n","d = len(data.vocab)\n","\n","rnn = RNN(num_inputs = d, num_hiddens=h, batch_size=n)\n","model = RNNLanguageModel(rnn, vocab_size=d, lr = 1)\n","trainer = d2l.Trainer(max_epochs=100, gradient_clip_val=1, num_gpus = 1)\n","# trainer.fit(model, data)\n","\n","\n"],"metadata":{"id":"o5jn7M8Gtt-C","executionInfo":{"status":"ok","timestamp":1676818146993,"user_tz":300,"elapsed":1447,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["#Concise implementation of RNN \n","\n","class RNNTorch(d2l.Module):\n","  def __init__(self, num_inputs, num_hiddens):\n","    super().__init__()\n","    self.save_hyperparameters()\n","    self.rnn = nn.RNN(num_inputs, num_hiddens)\n","  \n","  def forward(self, inputs, H = None):\n","    return self.rnn(inputs, H)\n","\n","class RNNLMTorch(d2l.RNNLMScratch):\n","  def init_params(self):\n","    self.linear = nn.LazyLinear(self.vocab_size)\n","\n","  def ouptut_layer(self, hiddens):\n","    return self.linear(hiddens).swapaxes(0,1)\n","\n","rnn = RNNTorch(num_inputs = d, num_hiddens = h)\n","model = RNNLMTorch(rnn, vocab_size = d, lr = 0.1)\n","model.predict('it has', 20, data.vocab)\n","  \n"],"metadata":{"id":"V4FyU_750u8A","colab":{"base_uri":"https://localhost:8080/","height":398},"executionInfo":{"status":"error","timestamp":1676818342723,"user_tz":300,"elapsed":331,"user":{"displayName":"James Nguyen (JK)","userId":"02481723335785605125"}},"outputId":"4d32b2ab-fb86-4d5b-ed73-e7093068cee3"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-0479a4c1ef83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mrnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNNTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_hiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNNLMTorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'it has'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, prefix, num_preds, vocab, device)\u001b[0m\n\u001b[1;32m    758\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Predict `num_preds` steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m                 \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midx_to_token\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36moutput_layer\u001b[0;34m(self, rnn_outputs)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;34m\"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_q\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mH\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrnn_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/d2l/torch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    738\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnn_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;34m\"\"\"Defined in :numref:`sec_rnn-scratch`\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW_hq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_q\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mH\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrnn_outputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1269\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1270\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'RNNLMTorch' object has no attribute 'W_hq'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"H_jHlNAgJnCc"},"execution_count":null,"outputs":[]}]}